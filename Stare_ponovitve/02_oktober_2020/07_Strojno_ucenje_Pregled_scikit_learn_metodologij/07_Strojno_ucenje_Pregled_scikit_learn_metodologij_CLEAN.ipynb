{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 07: Strojno uÄenje: Pregled Scikit-Learn metodologij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rects(N, ax, textprop={}, plt_=plt):\n",
    "    for i in range(N):\n",
    "        ax.add_patch(plt.Rectangle((0, i), 5, 0.7, fc='white'))\n",
    "        ax.add_patch(plt.Rectangle((5. * i / N, i), 5. / N, 0.7, fc='lightgray'))\n",
    "        ax.text(5. * (i + 0.5) / N, i + 0.35,\n",
    "                \"validation\\nset\", ha='center', va='center', **textprop)\n",
    "        ax.text(0, i + 0.35, \"trial {0}\".format(N - i),\n",
    "                ha='right', va='center', rotation=90, **textprop)\n",
    "    ax.set_xlim(-1, 6)\n",
    "    ax.set_ylim(-0.2, N + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N=30, err=0.8, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Representation in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "sns.pairplot(iris, hue='species', height=1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris.drop('species', axis=1)\n",
    "X_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_iris = iris['species']\n",
    "y_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "ax.axis('equal')\n",
    "\n",
    "# Draw features matrix\n",
    "ax.vlines(range(6), ymin=0, ymax=9, lw=1)\n",
    "ax.hlines(range(10), xmin=0, xmax=5, lw=1)\n",
    "font_prop = dict(size=12, family='monospace')\n",
    "ax.text(-1, -1, \"Feature Matrix ($X$)\", size=14)\n",
    "ax.text(0.1, -0.3, r'n_features $\\longrightarrow$', **font_prop)\n",
    "ax.text(-0.1, 0.1, r'$\\longleftarrow$ n_samples', rotation=90,\n",
    "        va='top', ha='right', **font_prop)\n",
    "\n",
    "# Draw labels vector\n",
    "ax.vlines(range(8, 10), ymin=0, ymax=9, lw=1)\n",
    "ax.hlines(range(10), xmin=8, xmax=9, lw=1)\n",
    "ax.text(7, -1, \"Target Vector ($y$)\", size=14)\n",
    "ax.text(7.9, 0.1, r'$\\longleftarrow$ n_samples', rotation=90,\n",
    "        va='top', ha='right', **font_prop)\n",
    "\n",
    "ax.set_ylim(10, -2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn's Estimator API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model validation the wrong way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model validation via Holdout sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "\n",
    "model.fit(X1, y1)\n",
    "\n",
    "\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model validation via cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "draw_rects(2, ax, textprop=dict(size=14), plt_=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "draw_rects(5, ax, textprop=dict(size=10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Bias-variance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_data()\n",
    "xfit = np.linspace(-0.1, 1.0, 1000)[:, None]\n",
    "model1 = PolynomialRegression(1).fit(X, y)\n",
    "model20 = PolynomialRegression(20).fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "ax[0].scatter(X.ravel(), y, s=40)\n",
    "ax[0].plot(xfit.ravel(), model1.predict(xfit), color='gray')\n",
    "ax[0].axis([-0.1, 1.0, -2, 14])\n",
    "ax[0].set_title('High-bias model: Underfits the data', size=14)\n",
    "\n",
    "ax[1].scatter(X.ravel(), y, s=40)\n",
    "ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray')\n",
    "ax[1].axis([-0.1, 1.0, -2, 14])\n",
    "ax[1].set_title('High-variance model: Overfits the data', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "X2, y2 = make_data(10, rseed=42)\n",
    "\n",
    "ax[0].scatter(X.ravel(), y, s=40, c='blue')\n",
    "ax[0].plot(xfit.ravel(), model1.predict(xfit), color='gray')\n",
    "ax[0].axis([-0.1, 1.0, -2, 14])\n",
    "ax[0].set_title('High-bias model: Underfits the data', size=14)\n",
    "ax[0].scatter(X2.ravel(), y2, s=40, c='red')\n",
    "ax[0].text(0.02, 0.98, \"training score: $R^2$ = {0:.2f}\".format(model1.score(X, y)),\n",
    "           ha='left', va='top', transform=ax[0].transAxes, size=14, color='blue')\n",
    "ax[0].text(0.02, 0.91, \"validation score: $R^2$ = {0:.2f}\".format(model1.score(X2, y2)),\n",
    "           ha='left', va='top', transform=ax[0].transAxes, size=14, color='red')\n",
    "\n",
    "ax[1].scatter(X.ravel(), y, s=40, c='blue')\n",
    "ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray')\n",
    "ax[1].axis([-0.1, 1.0, -2, 14])\n",
    "ax[1].set_title('High-variance model: Overfits the data', size=14)\n",
    "ax[1].scatter(X2.ravel(), y2, s=40, c='red')\n",
    "ax[1].text(0.02, 0.98, \"training score: $R^2$ = {0:.2g}\".format(model20.score(X, y)),\n",
    "           ha='left', va='top', transform=ax[1].transAxes, size=14, color='blue')\n",
    "ax[1].text(0.02, 0.91, \"validation score: $R^2$ = {0:.2g}\".format(model20.score(X2, y2)),\n",
    "           ha='left', va='top', transform=ax[1].transAxes, size=14, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "y1 = -(x - 0.5) ** 2\n",
    "y2 = y1 - 0.33 + np.exp(x - 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y2, lw=10, alpha=0.5, color='blue')\n",
    "ax.plot(x, y1, lw=10, alpha=0.5, color='red')\n",
    "\n",
    "ax.text(0.15, 0.2, \"training score\", rotation=45, size=16, color='blue')\n",
    "ax.text(0.2, -0.05, \"validation score\", rotation=20, size=16, color='red')\n",
    "\n",
    "ax.text(0.02, 0.1, r'$\\longleftarrow$ High Bias', size=18, rotation=90, va='center')\n",
    "ax.text(0.98, 0.1, r'$\\longleftarrow$ High Variance $\\longrightarrow$', size=18, rotation=90, ha='right', va='center')\n",
    "ax.text(0.48, -0.12, 'Best$\\\\longrightarrow$\\nModel', size=18, rotation=90, va='center')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-0.3, 0.5)\n",
    "\n",
    "ax.set_xlabel(r'model complexity $\\longrightarrow$', size=14)\n",
    "ax.set_ylabel(r'model score $\\longrightarrow$', size=14)\n",
    "\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "ax.set_title(\"Validation Curve Schematic\", size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N, err=1.0, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_data(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # plot formatting\n",
    "\n",
    "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y, \n",
    "                                          param_name='polynomialfeatures__degree', param_range=degree, cv=7)\n",
    "\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = make_data(200)\n",
    "plt.scatter(X2.ravel(), y2);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.arange(21)\n",
    "train_score2, val_score2 = validation_curve(PolynomialRegression(), X2, y2, \n",
    "                                          param_name='polynomialfeatures__degree', param_range=degree, cv=7)\n",
    "\n",
    "plt.plot(degree, np.median(train_score2, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score2, 1), color='red', label='validation score')\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', alpha=0.3, linestyle='dashed')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', alpha=0.3, linestyle='dashed')\n",
    "plt.legend(loc='lower center')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.linspace(0, 1, 1000)\n",
    "y1 = 0.75 + 0.2 * np.exp(-4 * N)\n",
    "y2 = 0.7 - 0.6 * np.exp(-4 * N)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y1, lw=10, alpha=0.5, color='blue')\n",
    "ax.plot(x, y2, lw=10, alpha=0.5, color='red')\n",
    "\n",
    "ax.text(0.2, 0.88, \"training score\", rotation=-10, size=16, color='blue')\n",
    "ax.text(0.2, 0.5, \"validation score\", rotation=30, size=16, color='red')\n",
    "\n",
    "ax.text(0.98, 0.45, r'Good Fit $\\longrightarrow$', size=18, rotation=90, ha='right', va='center')\n",
    "ax.text(0.02, 0.57, r'$\\longleftarrow$ High Variance $\\longrightarrow$', size=18, rotation=90, va='center')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel(r'training set size $\\longrightarrow$', size=14)\n",
    "ax.set_ylabel(r'model score $\\longrightarrow$', size=14)\n",
    "\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "ax.set_title(\"Learning Curve Schematic\", size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curves in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "for i, degree in enumerate([2, 9]):\n",
    "    N, train_lc, val_lc = learning_curve(PolynomialRegression(degree),\n",
    "                                         X, y, cv=7,\n",
    "                                         train_sizes=np.linspace(0.3, 1, 25))\n",
    "\n",
    "    ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score')\n",
    "    ax[i].plot(N, np.mean(val_lc, 1), color='red', label='validation score')\n",
    "    ax[i].hlines(np.mean([train_lc[-1], val_lc[-1]]), N[0], N[-1],\n",
    "                 color='gray', linestyle='dashed')\n",
    "\n",
    "    ax[i].set_ylim(0, 1)\n",
    "    ax[i].set_xlim(N[0], N[-1])\n",
    "    ax[i].set_xlabel('training size')\n",
    "    ax[i].set_ylabel('score')\n",
    "    ax[i].set_title('degree = {0}'.format(degree), size=14)\n",
    "    ax[i].legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation in Practice: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(21),\n",
    "              'linearregression__fit_intercept': [True, False],\n",
    "              'linearregression__normalize': [True, False]}\n",
    "\n",
    "grid = GridSearchCV(PolynomialRegression(), param_grid, cv=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "\n",
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = model.fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test, c='r');\n",
    "plt.axis(lim);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'price': 850000, 'rooms': 4, 'neighborhood': 'Queen Anne'},\n",
    "    {'price': 700000, 'rooms': 3, 'neighborhood': 'Fremont'},\n",
    "    {'price': 650000, 'rooms': 3, 'neighborhood': 'Wallingford'},\n",
    "    {'price': 600000, 'rooms': 2, 'neighborhood': 'Fremont'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Queen Anne': 1, 'Fremont': 2, 'Wallingford': 3};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer(sparse=False, dtype=int)\n",
    "vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer(sparse=True, dtype=int)\n",
    "vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical encoding using Label-Encoding and One-Hot-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting type of columns to 'category'\n",
    "bridge_df['Bridge_Types'] = bridge_df['Bridge_Types'].astype('category')\n",
    "# Assigning numerical values and storing in another column\n",
    "bridge_df['Bridge_Types_Cat'] = bridge_df['Bridge_Types'].cat.codes\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Assigning numerical values and storing in another column\n",
    "bridge_df['Bridge_Types_Cat'] = labelencoder.fit_transform(bridge_df['Bridge_Types'])\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(bridge_df[['Bridge_Types_Cat']]).toarray())\n",
    "\n",
    "# merge with main df bridge_df on key values\n",
    "bridge_df = bridge_df.join(enc_df)\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "\n",
    "# generate binary values using get_dummies\n",
    "dum_df = pd.get_dummies(bridge_df, columns=[\"Bridge_Types\"], prefix=[\"Type_is\"])\n",
    "\n",
    "# merge with main df bridge_df on key values\n",
    "bridge_df = bridge_df.join(dum_df)\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([4, 2, 1, 3, 7])\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = x[:, np.newaxis]\n",
    "model = LinearRegression().fit(X, y)\n",
    "yfit = model.predict(X)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yfit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X2 = poly.fit_transform(X)\n",
    "print(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X2, y)\n",
    "yfit = model.predict(X2)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yfit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "\n",
    "X = np.array([[ nan, 0,   3  ],\n",
    "              [ 3,   7,   9  ],\n",
    "              [ 3,   5,   2  ],\n",
    "              [ 4,   nan, 6  ],\n",
    "              [ 8,   8,   1  ]])\n",
    "\n",
    "y = np.array([14, 16, -1,  8, -5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X2 = imputer.fit_transform(X)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X2, y)\n",
    "model.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "                      PolynomialFeatures(degree=2),\n",
    "                      LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)  # X with missing values, from above\n",
    "print(y)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer: Predicting Credit Card Approvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
