{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fb6f98",
   "metadata": {},
   "source": [
    "# Adding external variables to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92ba2d",
   "metadata": {},
   "source": [
    "## Examining the SARIMAX model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d935c75",
   "metadata": {},
   "source": [
    "**The SARIMAX model simply adds a linear combination of exogenous variables to the\n",
    "SARIMA model. This allows us to model the impact of external variables on the future\n",
    "value of a time series.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb2e4c",
   "metadata": {},
   "source": [
    "## Forecasting the real GDP using the SARIMAX model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4532ead",
   "metadata": {},
   "source": [
    "### Exploring the exogenous variables of the US macroeconomics dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a47bf",
   "metadata": {},
   "source": [
    "Let’s load the US macroeconomics dataset and explore the different exogenous variables\n",
    "available to us to forecast the real GDP. This dataset is available with the statsmodels\n",
    "library, meaning that you do not need to download and read an external file.\n",
    "You can load the dataset using the datasets module of statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeccad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "macro_econ_data = sm.datasets.macrodata.load_pandas().data\n",
    "macro_econ_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2238014",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(macro_econ_data['realgdp'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Real GDP (k$)')\n",
    "\n",
    "plt.xticks(np.arange(0, 208, 16), np.arange(1959, 2010, 4))\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dfe9bb",
   "metadata": {},
   "source": [
    "This displays the entire DataFrame containing the US macroeconomics dataset.\n",
    "Table 9.1 describes the meaning of each variable. We have our target variable, or\n",
    "endogenous variable, which is the real GDP. Then we have 11 exogenous variables\n",
    "that can be used for forecasting, such as personal and federal consumption expenditures,\n",
    "interest rate, inflation rate, population, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cba45",
   "metadata": {},
   "source": [
    "- realgdp - Real gross domestic product (the target variable or endogenous variable)\n",
    "- realcons - Real personal consumption expenditure\n",
    "- realinv - Real gross private domestic investment\n",
    "- realgovt - Real federal consumption expenditure and investment\n",
    "- realdpi - Real private disposable income\n",
    "- cpi - Consumer price index for the end of the quarter\n",
    "- m1 - M1 nominal money stock\n",
    "- tbilrate - Quarterly monthly average of the monthly 3-month treasury bill\n",
    "- unemp - Unemployment rate\n",
    "- pop - Total population at the end of the quarter\n",
    "- infl - Inflation rate\n",
    "- realint - Real interest rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25d7ab",
   "metadata": {},
   "source": [
    "Of course, each of these variables may or may not be a good predictor of the real\n",
    "GDP. **We do not have to perform feature selection because the linear model will\n",
    "attribute a coefficient close to 0 for exogenous variables that are not significant in\n",
    "predicting the target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaa1cc",
   "metadata": {},
   "source": [
    "For the sake of simplicity and clarity, we will only work with six variables in this\n",
    "chapter: the real GDP, which is our target, and the next five variables listed in table as our exogenous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e63115",
   "metadata": {},
   "source": [
    "We can visualize how each variable behaves through time to see if we can discern\n",
    "any distinctive patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb76844",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, dpi=300, figsize=(11,6))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()[:6]):\n",
    "    data = macro_econ_data[macro_econ_data.columns[i+2]]\n",
    "    \n",
    "    ax.plot(data, color='black', linewidth=1)\n",
    "    ax.set_title(macro_econ_data.columns[i+2])\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines['top'].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "plt.setp(axes, xticks=np.arange(0, 208, 8), xticklabels=np.arange(1959, 2010, 2))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c62d3",
   "metadata": {},
   "source": [
    "There are two ways to work with exogenous variables for time series forecasting. First,\n",
    "we could train multiple models with various combinations of exogenous variables, and\n",
    "see which model generates the best forecasts. Alternatively, we can simply include all\n",
    "exogenous variables and stick to model selection using the AIC, as we know this yields\n",
    "a good-fitting model that does not overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07538ba5",
   "metadata": {},
   "source": [
    "### Caveat for using SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162db15",
   "metadata": {},
   "source": [
    "There is an important caveat that comes with the use of the SARIMAX model. Including\n",
    "external variables can potentially be beneficial, as you may find strong predictors\n",
    "for your target. However, you **might encounter issues when forecasting multiple timesteps\n",
    "into the future.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a9822",
   "metadata": {},
   "source": [
    "Recall that the SARIMAX model uses the SARIMA(p,d,q)(P,D,Q)m model and a linear\n",
    "combination of exogenous variables to predict one timestep into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c599de",
   "metadata": {},
   "source": [
    "But what if\n",
    "you wish to predict two timesteps into the future? While this is possible with a SARIMA\n",
    "model, the SARIMAX model requires us to forecast the exogenous variables too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b26969",
   "metadata": {},
   "source": [
    "**If your exogenous variable is easy to predict, meaning that it\n",
    "follows a known function that can be accurately predicted, there is no harm in forecasting\n",
    "the exogenous variable and using these forecasts to predict the target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e7564",
   "metadata": {},
   "source": [
    "In the end, there is no clear recommendation to predict only one timestep. It is\n",
    "dependent on the situation and the exogenous variables available. This is where your\n",
    "expertise as a data scientist and rigorous experimenting come into play. If you determine\n",
    "that your exogenous variable can be accurately predicted, you can recommend\n",
    "forecasting many timesteps into the future. Otherwise, your recommendation\n",
    "must be to predict one timestep at a time and justify your decision by explaining that\n",
    "errors will accumulate as more predictions are made, meaning that the forecasts will\n",
    "lose accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbfb68e",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237360f8",
   "metadata": {},
   "source": [
    "We are now ready to use the SARIMAX model to forecast the real GDP. Having\n",
    "explored the exogenous variables of the dataset, we will incorporate them into our\n",
    "forecasting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d2765",
   "metadata": {},
   "source": [
    "Before diving in, we must reintroduce the general modeling procedure. There are\n",
    "no major changes to the procedure. The only modification is that we will now fit a\n",
    "SARIMAX model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07900fe",
   "metadata": {},
   "source": [
    "We’ll first check for the stationarity of\n",
    "our target using the augmented Dickey-Fuller (ADF) test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909333e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = macro_econ_data['realgdp']\n",
    "exog = macro_econ_data[['realcons', 'realinv', 'realgovt', 'realdpi', 'cpi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a499d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_fuller_result = adfuller(target)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a34038",
   "metadata": {},
   "source": [
    "This returns an ADF statistic of 1.75 and a p-value of 1.00. Since the ADF statistic is not\n",
    "a large negative number, and the p-value is larger than 0.05, we cannot reject the null\n",
    "hypothesis and conclude that the series is not stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c804810",
   "metadata": {},
   "source": [
    "Therefore, we must apply a transformation and test for stationarity again. Here we\n",
    "will difference the series once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_diff = target.diff()\n",
    "\n",
    "ad_fuller_result = adfuller(target_diff[1:])\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c934da3",
   "metadata": {},
   "source": [
    "This now returns an ADF statistic of –6.31 and p-value of 3.32 × 10–8. With a large negative\n",
    "ADF statistic and a p-value smaller than 0.05, we can reject the null hypothesis\n",
    "and conclude that the series is now stationary. Therefore, we know that d = 1. Since we\n",
    "did not need to take a seasonal difference to make the series stationary, D = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be2dc5",
   "metadata": {},
   "source": [
    "We will now define the optimize_SARIMAX function, which will fit all unique combinations\n",
    "of the model and return a DataFrame in ascending order of AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a86793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_SARIMAX(endog: Union[pd.Series, list], exog: Union[pd.Series, list], order_list: list, d: int, D: int, s: int) -> pd.DataFrame:\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for order in tqdm(order_list):\n",
    "        try: \n",
    "            model = SARIMAX(\n",
    "                endog,\n",
    "                exog,\n",
    "                order=(order[0], d, order[1]),\n",
    "                seasonal_order=(order[2], D, order[3], s),\n",
    "                simple_differencing=False).fit(disp=False)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        aic = model.aic\n",
    "        results.append([order, aic])\n",
    "        \n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.columns = ['(p,q,P,Q)', 'AIC']\n",
    "    \n",
    "    #Sort in ascending order, lower AIC is better\n",
    "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625c13e",
   "metadata": {},
   "source": [
    "Next we’ll define the range of possible values for the orders p, q, P, and Q. We’ll try values\n",
    "from 0 to 3, but feel free to try a different set of values. Also, since the data is collected\n",
    "quarterly, m = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = range(0, 4, 1)\n",
    "d = 1\n",
    "q = range(0, 4, 1)\n",
    "P = range(0, 4, 1)\n",
    "D = 0\n",
    "Q = range(0, 4, 1)\n",
    "s = 4\n",
    "\n",
    "parameters = product(p, q, P, Q)\n",
    "parameters_list = list(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162cf22",
   "metadata": {},
   "source": [
    "To train the model, we will use the first 200 instances of both the target and exogenous\n",
    "variables. We’ll then run the optimize_SARIMAX function and select the model\n",
    "with the lowest AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49759b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "target_train = target[:200]\n",
    "exog_train = exog[:200]\n",
    "\n",
    "result_df = optimize_SARIMAX(target_train, exog_train, parameters_list, d, D, s)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2da9cb",
   "metadata": {},
   "source": [
    "Once it’s completed, the function returns the verdict that the SARIMAX(3,1,3)(0,0,0)4\n",
    "model is the model with the lowest AIC. Notice that the seasonal component of the\n",
    "model has only orders of 0. This makes sense, as there is no visible seasonal pattern in the plot of real GDP, as shown in figure 9.4. Therefore, the seasonal component is\n",
    "null, and we have an ARIMAX(3,1,3) model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961597dd",
   "metadata": {},
   "source": [
    "Now we can fit the selected model and display a summary table to see the coefficients\n",
    "associated with our exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d349ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SARIMAX(target_train, exog_train, order=(3,1,3), seasonal_order=(0,0,0,4), simple_differencing=False)\n",
    "best_model_fit = best_model.fit(disp=False)\n",
    "print(best_model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee59b6",
   "metadata": {},
   "source": [
    "You’ll notice that all exogenous variables have a p-value smaller than\n",
    "0.05, except for realdpi, which has a p-value of 0.712. This means that the coefficient\n",
    "of realdpi is not significantly different from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1133ff",
   "metadata": {},
   "source": [
    "However, the coefficient is kept in the model, as the p-value does not determine\n",
    "the relevance of this predictor in forecasting our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fit.plot_diagnostics(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a74d57b",
   "metadata": {},
   "source": [
    "Moving on with the modeling procedure, we’ll now study the residuals of the model,\n",
    "which are shown in figure 9.6. Everything points to the residuals being completely\n",
    "random, just like white noise. Our model passes the visual check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4befc9",
   "metadata": {},
   "source": [
    "Now we’ll apply the Ljung-Box test to make sure the residuals are not correlated. We\n",
    "therefore want to see p-values that are greater than 0.05, since the null hypothesis of\n",
    "the Ljung-Box test is that residuals are independent and uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f41a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = best_model_fit.resid\n",
    "\n",
    "res = acorr_ljungbox(residuals, np.arange(1, 11, 1))\n",
    "print(list(res[\"lb_pvalue\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c01d77",
   "metadata": {},
   "source": [
    "All the p-values are greater than 0.05. Therefore, we do not reject the null hypothesis,\n",
    "and we conclude that the residuals are independent and uncorrelated. Having passed\n",
    "both residual checks, our model can be used for forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f0957",
   "metadata": {},
   "source": [
    "As mentioned before, the caveat of **using a SARIMAX model is that it is reasonable\n",
    "to predict only the next timestep, to avoid predicting the exogenous variables as well,\n",
    "which would lead us to accumulate prediction errors in the final forecast.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a16bc",
   "metadata": {},
   "source": [
    "Instead, to test our model, we predict the next timestep multiple times and average\n",
    "the errors of each prediction. This is done using the rolling_forecast function. As a baseline model, we will use\n",
    "the last known value method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_forecast(endog: Union[pd.Series, list], exog: Union[pd.Series, list], train_len: int, horizon: int, window: int, method: str) -> list:\n",
    "    \n",
    "    total_len = train_len + horizon\n",
    "\n",
    "    if method == 'last':\n",
    "        pred_last_value = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            last_value = endog[:i].iloc[-1]\n",
    "            pred_last_value.extend(last_value for _ in range(window))\n",
    "            \n",
    "        return pred_last_value\n",
    "    \n",
    "    elif method == 'SARIMAX':\n",
    "        pred_SARIMAX = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            model = SARIMAX(endog[:i], exog[:i], order=(3,1,3), seasonal_order=(0,0,0,4), simple_differencing=False)\n",
    "            res = model.fit(disp=False)\n",
    "            predictions = res.get_prediction(exog=exog)\n",
    "            oos_pred = predictions.predicted_mean.iloc[-window:]\n",
    "            pred_SARIMAX.extend(oos_pred)\n",
    "            \n",
    "        return pred_SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa626ae",
   "metadata": {},
   "source": [
    "The recursive_forecast function allows us to predict the next timestep over a certain\n",
    "period of time. Specifically, we will use it to forecast the next timestep starting in\n",
    "2008 and going to the third quarter of 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff854e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = target[:196]\n",
    "target_test = target[196:]\n",
    "\n",
    "pred_df = pd.DataFrame({'actual': target_test})\n",
    "\n",
    "TRAIN_LEN = len(target_train)\n",
    "HORIZON = len(target_test)\n",
    "WINDOW = 1\n",
    "\n",
    "pred_last_value = recursive_forecast(target, exog, TRAIN_LEN, HORIZON, WINDOW, 'last')\n",
    "pred_SARIMAX = recursive_forecast(target, exog, TRAIN_LEN, HORIZON, WINDOW, 'SARIMAX')\n",
    "\n",
    "pred_df['pred_last_value'] = pred_last_value\n",
    "pred_df['pred_SARIMAX'] = pred_SARIMAX\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e12fb",
   "metadata": {},
   "source": [
    "With the predictions done, we can visualize which model has the lowest mean absolute\n",
    "percentage error (MAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32710950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_last = mape(pred_df.actual, pred_df.pred_last_value)\n",
    "mape_SARIMAX = mape(pred_df.actual, pred_df.pred_SARIMAX)\n",
    "\n",
    "print(mape_last, mape_SARIMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a29365",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = ['naive last value', 'SARIMAX']\n",
    "y = [mape_last, mape_SARIMAX]\n",
    "\n",
    "ax.bar(x, y, width=0.4)\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('MAPE (%)')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "for index, value in enumerate(y):\n",
    "    plt.text(x=index, y=value + 0.05, s=str(round(value,2)), ha='center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83446ec7",
   "metadata": {},
   "source": [
    "In figure 9.7 you’ll see that the SARIMAX model is the winning model by only 0.04%.\n",
    "You’ll appreciate the importance of a baseline here, as both methods achieve an\n",
    "extremely low MAPE, showing that the SARIMAX model is only slightly better than\n",
    "simply predicting the last value. This is where the business context comes into play. In\n",
    "our case, since we are predicting the real GDP of the United States, a difference of\n",
    "0.04% represents thousands of dollars. This difference might be relevant in this particular\n",
    "context, justifying the use of the SARIMAX model, even though it is only\n",
    "slightly better than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44c4de",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dfb88f",
   "metadata": {},
   "source": [
    "Those models **work particularly well when you have small\n",
    "datasets (usually less than 10,000 data points)**, and when the **seasonal period is\n",
    "monthly, quarterly, or yearly**. \n",
    "\n",
    "In situations where you have daily seasonality or where\n",
    "the dataset is very large (more than 10,000 data points), those statistical models\n",
    "become very slow, and their performance degrades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559643ab",
   "metadata": {},
   "source": [
    "Thus, we turn to deep learning. Deep learning is a subset of machine learning\n",
    "that focuses on building models on the neural network architecture. Deep learning\n",
    "has the advantage that it tends to perform better as more data is available, making\n",
    "it a great choice for forecasting high-dimensional time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c0481",
   "metadata": {},
   "source": [
    "Deep learning shines when we have large complex datasets. In those situations, deep\n",
    "learning can leverage all the available data to infer relationships between each feature\n",
    "and the target, usually resulting in good forecasts.\n",
    "\n",
    "In the context of time series, a dataset is considered to be large when we have\n",
    "more than 10,000 data points. Of course, this is an approximation rather than a hardset\n",
    "limit, so if you have 8,000 data points, deep learning could be a viable option.\n",
    "When the size of the dataset is large, any declination of the SARIMAX model will take\n",
    "a long time to fit, which is not ideal for model selection, as we usually fit many models\n",
    "during that step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c26782",
   "metadata": {},
   "source": [
    "**If your data has multiple seasonal periods, the SARIMAX model cannot be used.**\n",
    "For example, suppose you must forecast the hourly temperature. It is reasonable to\n",
    "assume that there will be daily seasonality, as temperature tends to be lower at night\n",
    "and higher during the day, but there is also yearly seasonality, due to temperatures\n",
    "being lower in winter and higher during summer. In such a case, deep learning can be\n",
    "used to leverage the information from both seasonal periods to make forecasts. In\n",
    "fact, from experience, fitting a SARIMA model in such a case will usually result in\n",
    "residuals that are not normally distributed and still correlated, meaning that the\n",
    "model cannot be used at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f3867",
   "metadata": {},
   "source": [
    "Ultimately, **deep learning is used either when statistical models take too much time\n",
    "to fit or when they result in correlated residuals that do not approximate white noise.**\n",
    "This can be due to the fact that there is another seasonal period that cannot be considered\n",
    "in the model, or simply because there is a nonlinear relationship between the\n",
    "features and the target. In those cases, deep learning models can be used to capture this\n",
    "nonlinear relationship, and they have the added **advantage of being very fast to train.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
